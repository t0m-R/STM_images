{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import omicronscala\n",
    "import spym\n",
    "import xarray\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from kmeans_pytorch import kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePickle(obj, filename):\n",
    "    with open('{}.pkl'.format(filename), 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "        \n",
    "def loadPickle(filename):\n",
    "    with open('{}.pkl'.format(filename), 'rb') as file:\n",
    "        obj = pickle.load(file)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits https://github.com/aayushmnit/Deep_learning_explorations\n",
    "class Hook():\n",
    "    \"Create a hook on `m` with `hook_func`.\"\n",
    "    def __init__(self, m:nn.Module, hook_func:HookFunc, is_forward:bool=True, detach:bool=True):\n",
    "        self.hook_func,self.detach,self.stored = hook_func,detach,None\n",
    "        f = m.register_forward_hook if is_forward else m.register_backward_hook\n",
    "        self.hook = f(self.hook_fn)\n",
    "        self.removed = False\n",
    "\n",
    "    def hook_fn(self, module:nn.Module, input:Tensors, output:Tensors):\n",
    "        \"Applies `hook_func` to `module`, `input`, `output`.\"\n",
    "        if self.detach:\n",
    "            input  = (o.detach() for o in input ) if is_listy(input) else input.detach()\n",
    "            output = (o.detach() for o in output) if is_listy(output) else output.detach()\n",
    "        self.stored = self.hook_func(module, input, output)\n",
    "\n",
    "    def remove(self):\n",
    "        \"Remove the hook from the model.\"\n",
    "        if not self.removed:\n",
    "            self.hook.remove()\n",
    "            self.removed=True\n",
    "\n",
    "    def __enter__(self, *args): return self\n",
    "    def __exit__(self, *args): self.remove()\n",
    "        \n",
    "def get_output(module, input_value, output):\n",
    "    return output.flatten(1)\n",
    "\n",
    "def get_input(module, input_value, output):\n",
    "    return list(input_value)[0]\n",
    "\n",
    "def get_named_module_from_model(model, name):\n",
    "    for n, m in model.named_modules():\n",
    "        if n == name:\n",
    "            return m\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_df():\n",
    "    \"create DataFrame for ImageList loader\"\n",
    "    data_df = loadPickle('clean_stm')\n",
    "    data_df['path'] = [ 'data/train/{}.png'.format(x) for x in data_df.index.values ]\n",
    "    random = []\n",
    "    for category in data_df['Categories'].unique():\n",
    "        if len(category.split(',')) > 1 or category == '':\n",
    "            random.append(category) \n",
    "    category_label = data_df.Categories.astype(\"category\").cat.codes\n",
    "    dataset = [ 'train' for x in range(len(data_df))]\n",
    "    category = data_df['Categories']\n",
    "    data_df['category_label'] = category_label\n",
    "    data_df['dataset'] = dataset\n",
    "    data_df['category'] = category\n",
    "    data_df['is_valid'] = [ True if x.Categories == 'mixed' else False for _,x in data_df.iterrows()]\n",
    "    data_df = data_df[['path', 'category_label', 'dataset', 'category', 'is_valid']][:]\n",
    "    return data_df\n",
    "\n",
    "def get_dict_category_labels(data_df):\n",
    "    \"create dictionary that maps categories with their labels\"\n",
    "    tmp = data_df.groupby(['category','category_label']).size().reset_index().rename(columns={0:'count'})\n",
    "    ct = tmp['category'].to_list()\n",
    "    ctl = tmp['category_label'].to_list()\n",
    "    dict_category_labels = dict(zip(ctl,ct))\n",
    "    return dict_category_labels\n",
    "\n",
    "def get_imgs_data(data_df, images_path):\n",
    "    data_source = ImageList.from_df(df=data_df, path=images_path, cols=['path']).split_from_df(col='is_valid').label_from_df(cols='category_label')\n",
    "    tmfs = get_transforms()\n",
    "    data = data_source.transform(tmfs, size=224).databunch(bs=32).normalize(imagenet_stats)\n",
    "    return data_source, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_features_df(linear_output_layer, inference_dataloader):\n",
    "    img_repr_map = {}\n",
    "\n",
    "    with Hook(linear_output_layer, get_input, True, True) as hook:\n",
    "        for i, (xb, yb) in enumerate(inference_dataloader):\n",
    "            bs = xb.shape[0]\n",
    "            if bs != 32:\n",
    "                img_ids = inference_dataloader.items[-bs:]\n",
    "            else:\n",
    "                img_ids = inference_dataloader.items[i*bs:(i+1)*bs]\n",
    "            result = model.eval()(xb)\n",
    "            img_reprs = hook.stored.cpu().numpy()\n",
    "            img_reprs = img_reprs.reshape(bs, -1)\n",
    "            for img_id, img_repr in zip(img_ids, img_reprs):\n",
    "                img_repr_map[img_id] = img_repr\n",
    "    \n",
    "    img_repr_df = pd.DataFrame(img_repr_map.items(), columns=['img_path', 'img_repr'])\n",
    "    img_repr_df['ID'] = [ x.split('/')[-1].split('.')[0] for x in img_repr_df['img_path'] ]\n",
    "    img_repr_df.set_index('ID', inplace=True)\n",
    "    img_repr_df['label'] = [inference_data.classes[x] for x in inference_data.train_ds.y.items[0:img_repr_df.shape[0]]]\n",
    "    img_repr_df['label_id'] = inference_data.train_ds.y.items[0:img_repr_df.shape[0]]\n",
    "    return img_repr_df\n",
    "\n",
    "def torch_save(img_repr_df,fname):\n",
    "    img_ft_df = img_repr_df.copy()\n",
    "    img_ft_df['ID'] = [ x.split('/')[-1].split('.')[0] for x in img_repr_df['img_path'] ]\n",
    "    img_ft_df.set_index('ID', inplace=True)\n",
    "    img_ft_df.drop(columns=['label', 'label_id'], inplace=True)\n",
    "    tmp = img_ft_df['img_repr'].to_numpy()\n",
    "    tmp = np.stack(tmp)\n",
    "    xx = torch.from_numpy(tmp)\n",
    "    torch.save(xx, '{}'.format(fname)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe\n",
    "data_df = get_data_df()\n",
    "\n",
    "# mapping categories -> labels\n",
    "dict_category_labels = get_dict_category_labels()\n",
    "savePickle(dict_category_labels,'labels_dict')\n",
    "\n",
    "#data folder path\n",
    "images_path = Path('path_to_data_folder')\n",
    "\n",
    "# ImageLoader, Images\n",
    "data_source, data = get_imgs_data(data_df, images_path)\n",
    "\n",
    "#get resnet pretrained on imagenet\n",
    "learner = cnn_learner(data, models.resnet50, pretrained=True)\n",
    "model = learner.model\n",
    "\n",
    "#select layer for feature extraction\n",
    "linear_output_layer = get_named_module_from_model(model, '1.4')\n",
    "\n",
    "#prepare images and dataloader\n",
    "inference_data = data_source.transform(tmfs, size=224).databunch(bs=32).normalize(imagenet_stats)\n",
    "inference_dataloader = inference_data.train_dl.new(shuffle=False,drop_last=False)\n",
    "\n",
    "# get features df\n",
    "img_repr_df = get_img_features_df(linear_output_layer, inference_dataloader)\n",
    "savePickle(img_repr_df, \"stm_features_df\")\n",
    "\n",
    "# simpler df\n",
    "df_features = img_repr_df[['img_repr', 'label']]\n",
    "savePickle(df_features, \"stm_df_features\")\n",
    "torch_save(img_repr_df, 'S_features_resnet50_4096')\n",
    "\n",
    "# categories distribution\n",
    "len_dict = {}\n",
    "for k,v in dict_category_labels.items():\n",
    "    ldf = len(img_repr_df[img_repr_df['label']== k])/len(img_repr_df)\n",
    "    len_dict[v] = ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def get_similar_images(img_index, n=10):\n",
    "    base_img_id, base_vector, base_label, _  = img_repr_df.loc[str(img_index)][:]\n",
    "    cosine_similarity = 1 - img_repr_df['img_repr'].apply(lambda x: cosine(x, base_vector))\n",
    "    similar_img_ids = np.argsort(cosine_similarity)[-n-1:-1][::-1]\n",
    "\n",
    "    return base_img_id, base_label, img_repr_df.iloc[similar_img_ids]\n",
    "\n",
    "def get_similar_images_euclidean(img_index, n=10):\n",
    "    base_img_id, base_vector, base_label, _  = img_repr_df.loc[str(img_index)][:]\n",
    "    similarity = img_repr_df['img_repr'].apply(lambda x: euclidean(x, base_vector))\n",
    "    similar_img_ids = np.argsort(similarity)[::][:n]\n",
    "    return base_img_id, base_label, img_repr_df.iloc[similar_img_ids]\n",
    "\n",
    "def show_similar_images(similar_images_df):\n",
    "    images = [open_image(img_id) for img_id in similar_images_df['img_path']]\n",
    "    categories = [learner.data.train_ds.y.reconstruct(y) for y in similar_images_df['label_id']]\n",
    "    return learner.data.show_xys(images, categories)\n",
    "\n",
    "def cosine_stats(df, trials=100, n_imgs=100):\n",
    "    cstats = {}\n",
    "    cats = df['label'].unique()\n",
    "    for c in cats:\n",
    "        start = time.time()\n",
    "\n",
    "        c_imgs = []\n",
    "        c_dfs = []\n",
    "        rdict = {}\n",
    "        ldf = len(df[df['label']== c])\n",
    "        if ldf < trials:\n",
    "            print('skipping {}: requested {} samples out of {} images'.format(dict_category_labels[c], trials, ldf))\n",
    "            continue\n",
    "        tmp_df = df[df['label']== c].sample(trials)\n",
    "        for i, row in tmp_df.iterrows():\n",
    "            base_image, base_label, similar_images_df = get_similar_images(i, n_imgs)\n",
    "            c_imgs.append(i)\n",
    "            c_dfs.append(similar_images_df)\n",
    "            results = similar_images_df.groupby('label').size().reset_index(name='N imgs').sort_values(by='N imgs', ascending=False)\n",
    "            results['label'] = [ dict_category_labels[x] for x in results['label'] ]\n",
    "            lab = results['label'].to_list()\n",
    "            nimgs = results['N imgs'].to_list()\n",
    "            for k,v in zip(lab, nimgs):\n",
    "                if k not in rdict.keys():\n",
    "                    rdict[k] = v\n",
    "                else:\n",
    "                    rdict[k] += v\n",
    "        clabel = dict_category_labels[c]\n",
    "        cstats[c] = {'ID': c_imgs, 'dfs': c_dfs, 'res': rdict, 'label': clabel, 'len': ldf}\n",
    "        end = time.time()\n",
    "        print(f'{end - start} secs')\n",
    "    return cstats\n",
    "\n",
    "def euclidean_stats(df, trials=100, n_imgs=100):\n",
    "    cstats = {}\n",
    "    cats = df['label'].unique()\n",
    "    for c in cats:\n",
    "        start = time.time()\n",
    "\n",
    "        c_imgs = []\n",
    "        c_dfs = []\n",
    "        rdict = {}\n",
    "        ldf = len(df[df['label']== c])\n",
    "        if ldf < trials:\n",
    "            print('skipping {}: requested {} samples out of {} images'.format(dict_category_labels[c], trials, ldf))\n",
    "            continue\n",
    "        tmp_df = df[df['label']== c].sample(trials)\n",
    "        for i, row in tmp_df.iterrows():\n",
    "            base_image, base_label, similar_images_df = get_similar_images_euclidean(i, n_imgs)\n",
    "            c_imgs.append(i)\n",
    "            c_dfs.append(similar_images_df)\n",
    "            results = similar_images_df.groupby('label').size().reset_index(name='N imgs').sort_values(by='N imgs', ascending=False)\n",
    "            results['label'] = [ dict_category_labels[x] for x in results['label'] ]\n",
    "            lab = results['label'].to_list()\n",
    "            nimgs = results['N imgs'].to_list()\n",
    "            for k,v in zip(lab, nimgs):\n",
    "                if k not in rdict.keys():\n",
    "                    rdict[k] = v\n",
    "                else:\n",
    "                    rdict[k] += v\n",
    "        clabel = dict_category_labels[c]\n",
    "        cstats[c] = {'ID': c_imgs, 'dfs': c_dfs, 'res': rdict, 'label': clabel, 'len': ldf}\n",
    "        end = time.time()\n",
    "        print(f'{end - start} secs')\n",
    "    return cstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_date(new_date, start_date):\n",
    "    if new_date == start_date:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_same_offset(xoff,yoff,start_xoff, start_yoff,rounded=False):\n",
    "    if rounded: \n",
    "        if (int(xoff) == int(start_xoff)) and (int(yoff) == int(start_yoff)):\n",
    "            return True\n",
    "    else:\n",
    "        if (xoff == start_xoff) and (yoff == start_yoff):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def filter_ids(ids, ID, check_off=False, rounded=False):\n",
    "    good_ones = [int(ID)]\n",
    "    for i in ids.index.tolist():\n",
    "        x,y,d = stm.loc[int(i)][[\"XOffset\",\"YOffset\",\"Date\"]].tolist()\n",
    "        g = 1\n",
    "        for j in good_ones:\n",
    "            xj,yj,dj=stm.loc[int(j)][[\"XOffset\",\"YOffset\",\"Date\"]].tolist()\n",
    "            if is_same_date(d,dj):\n",
    "                if check_off:\n",
    "                    if is_same_offset(x,y,xoff,yoff,rounded):\n",
    "                        g = -1\n",
    "                else:\n",
    "                    g = -1\n",
    "        if g > 0:\n",
    "            good_ones.append(int(i))\n",
    "    if len(good_ones)>25:\n",
    "        good_ones = good_ones[1:25]\n",
    "    else:\n",
    "        good_ones = good_ones[1:]\n",
    "    return good_ones\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cosine(df, ID, listID, fsize=8, dpi=40):\n",
    "    start_img = imgID(df,int(ID))\n",
    "    imgs = df.loc[df.index.intersection(listID)]\n",
    "    images = []\n",
    "    for i, image in imgs.iterrows():\n",
    "        try:\n",
    "            images.append(show_img(path,image))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    plt.ioff()\n",
    "    rows=5\n",
    "    cols=5\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=((fsize*cols),(fsize*rows)))\n",
    "    c = 0\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if (i==2) and (j==2):\n",
    "                start_img[1].plot(ax=axs[i,j], cmap='afmhot', add_colorbar=False )\n",
    "                axs[i,j].set_title(r\"[{}] {} $\\bf{{{}}}$\".format(start_img[0]['Date'],start_img[0]['TF0_Filename'], start_img[0].name), fontsize=20)\n",
    "                for item in ([axs[i,j].xaxis.label, axs[i,j].yaxis.label] +\n",
    "                      axs[i,j].get_xticklabels() + axs[i,j].get_yticklabels()):\n",
    "                    item.set_fontsize(fsize*2)\n",
    "            else:\n",
    "                if c < len(images):\n",
    "                    images[c][1].plot(ax=axs[i,j], cmap='afmhot', add_colorbar=False )\n",
    "                    axs[i,j].set_title(r\"[{}] {} $\\bf{{{}}}$\".format(images[c][0]['Date'],images[c][0]['TF0_Filename'], images[c][0].name), fontsize=20)\n",
    "                    for item in ([axs[i,j].xaxis.label, axs[i,j].yaxis.label] +\n",
    "                          axs[i,j].get_xticklabels() + axs[i,j].get_yticklabels()):\n",
    "                        item.set_fontsize(fsize*2)\n",
    "                    c +=1\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n",
    "    Path('cosine3/{}'.format(start_img[0]['Categories'])).mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig('cosine3/{}/{}.png'.format(start_img[0]['Categories'],start_img[0].name), dpi=dpi)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(path, img):\n",
    "    file = img['ImageOriginalName']\n",
    "    ds = omicronscala.to_dataset(Path(path+file))\n",
    "    tf = ds.Z_Forward\n",
    "    tf.spym.plane()\n",
    "    tf.spym.align()\n",
    "    tf.spym.plane()\n",
    "    tf.spym.fixzero(to_mean=True)\n",
    "    return [img, tf]\n",
    "\n",
    "def imgID(df, ID):\n",
    "    img = df.loc[ID]\n",
    "    file = img.ImageOriginalName\n",
    "    ds = omicronscala.to_dataset(Path(path+file))\n",
    "    tf = ds.Z_Forward\n",
    "    tf.spym.plane()\n",
    "    tf.spym.align()\n",
    "    tf.spym.plane()\n",
    "    tf.spym.fixzero(to_mean=True)\n",
    "    return [img, tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cosine_results(stats):\n",
    "    plt.ioff()\n",
    "    rows = 4\n",
    "    cols = 4\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(2+(10*cols),10*rows))\n",
    "    fig.suptitle('Cosine similarity for 100 trials of 100 images for each category', fontsize=36)\n",
    "    ids = list(stats.keys())\n",
    "    c = 0\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if c < len(ids):\n",
    "                k = ids[c]\n",
    "                tk = list(stats[k]['res'].keys())\n",
    "                tv = list(stats[k]['res'].values())\n",
    "                tmax = max(tv)\n",
    "                tv = [x/tmax for x in tv]\n",
    "                l = stats[k]['label']\n",
    "                cmap = ['g' if x == l else 'b' for x in tk ]\n",
    "                axs[i,j].bar(tk, tv, color=cmap)\n",
    "                axs[i,j].set_title('{}'.format(l), fontsize=28)\n",
    "                for item in ([axs[i,j].xaxis.label, axs[i,j].yaxis.label] +\n",
    "                      axs[i,j].get_xticklabels() + axs[i,j].get_yticklabels()):\n",
    "                    item.set_fontsize(16)\n",
    "                axs[i,j].set_ylabel('N images')\n",
    "                for tick in axs[i,j].get_xticklabels():\n",
    "                    tick.set_rotation(90)\n",
    "                c += 1\n",
    "            else:\n",
    "                axs[i,j].axis('off')\n",
    "                c += 1\n",
    "                \n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    fig.show()\n",
    "    fig.savefig('cosine_S_100x100.png')\n",
    "\n",
    "    \n",
    "def plot_cosine_results_norm(stats, prefix, trials, n_imgs, len_dict):\n",
    "    plt.ioff()\n",
    "    rows = 4\n",
    "    cols = 4\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(2+(10*cols),10*rows))\n",
    "    fig.suptitle('{} similarity for {} trials of {} images for each category'.format(prefix, trials, n_imgs), fontsize=36)\n",
    "    ids = list(stats.keys())\n",
    "    c = 0\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if c < len(ids):\n",
    "                k = ids[c]\n",
    "                tk = list(stats[k]['res'].keys())\n",
    "                tv = list(stats[k]['res'].values())\n",
    "                tp = [ len_dict[x] for x in tk]\n",
    "                tmax = sum(tv)\n",
    "                tv = [x/tmax for x in tv]\n",
    "                l = stats[k]['label']\n",
    "                cmap = ['g' if x == l else 'b' for x in tk ]\n",
    "                X = np.arange(len(tk))\n",
    "                w = 0.3\n",
    "                axs[i,j].bar(X+0.0, tv, w, color=cmap)\n",
    "                axs[i,j].bar(X+0.3, tp, w, color='r')\n",
    "                axs[i,j].set_xticks(X)\n",
    "                axs[i,j].set_xticklabels(tk)\n",
    "                axs[i,j].set_title('{}'.format(l), fontsize=28)\n",
    "                for item in ([axs[i,j].xaxis.label, axs[i,j].yaxis.label] +\n",
    "                      axs[i,j].get_xticklabels() + axs[i,j].get_yticklabels()):\n",
    "                    item.set_fontsize(16)\n",
    "                axs[i,j].set_ylabel('N images')\n",
    "                for tick in axs[i,j].get_xticklabels():\n",
    "                    tick.set_rotation(90)\n",
    "                c += 1\n",
    "            else:\n",
    "                axs[i,j].axis('off')\n",
    "                c += 1\n",
    "                \n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    fig.show()\n",
    "    fig.savefig('{}_S_{}x{}.png'.format(prefix, trials, n_imgs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to original imgs\n",
    "path = 'path_to_images'\n",
    "\n",
    "#load stm metadata df\n",
    "stm = loadPickle('clean_stm')\n",
    "\n",
    "# good images manually selected\n",
    "goods_dict = { \"N_Gr_Ni111\": [87980, 87931, 88019, 87795, 84551, 84568, 87048, 83206, \n",
    "87912, 87774], \"Gr_Ni111\" : [85804, 83502, 83080, 83018, 83005, 82729, 82061, 50736, 50701, \n",
    "49062], \"Gr_Ni100\": [77857, 77795, 77809, 77690, 77696, 79863, 77649, 77626, 79779, \n",
    "79729],\"NFFA_ID617\": [86169, 86687, 86374, 83699, 83734, 84700, 83880, 84133, \n",
    "85763, 85800]}\n",
    "\n",
    "# similarity search with filtering for each image\n",
    "for k,v in goods_dict.items():\n",
    "    print('\\n{}'.format(k))\n",
    "    for ID in v:\n",
    "        print('\\t{}'.format(ID))\n",
    "        _, _, ids = get_similar_images(ID, 250)\n",
    "        list_ID = filter_ids(ids,ID,check_off=True,rounded=True)\n",
    "        plot_cosine(stm,ID, list_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single image similarity example\n",
    "base_image, base_label, similar_images_df = get_similar_images_euclidean(44148, 100)\n",
    "print(base_label)\n",
    "print(base_image)\n",
    "open_image(base_image)\n",
    "show_similar_images(similar_images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features validation by statistical analysis on extracted images from similarity search\n",
    "\n",
    "stats2 = cosine_stats(img_repr_df, 500, 20)\n",
    "plot_cosine_results_norm(stats2, 500, 20, len_dict)\n",
    "savePickle(stats2, 'cosine_500_20')\n",
    "\n",
    "stats3 = euclidean_stats(img_repr_df, 100, 100)\n",
    "plot_cosine_results_norm(stats3, 'euclidean', 100, 100, len_dict)\n",
    "plot_cosine_results_norm(stats3, 100, 100, len_dict)\n",
    "savePickle(stats3, 'euclidean_100_100')\n",
    "\n",
    "stats4 = euclidean_stats(img_repr_df, 500, 20)\n",
    "plot_cosine_results_norm(stats4, 'euclidean', 500, 20, len_dict)\n",
    "savePickle(stats4, 'euclidean_500_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def compute_ID (X):\n",
    "    N = X.shape[0]\n",
    "    ngbr= NearestNeighbors(n_neighbors=3, algorithm='kd_tree', n_jobs=-1).fit(X)\n",
    "    nn_distances, nn_indices = ngbr.kneighbors(X)\n",
    "    mu = nn_distances[:,2] / nn_distances[:,1]\n",
    "    i_sorted = np.argsort(mu)\n",
    "    F_emp = np.zeros(N, dtype=float)\n",
    "    F_emp[i_sorted] = [i /N for i in range(N)]\n",
    "    x = np.log(mu).reshape(-1,1)\n",
    "    y = -np.log(1. - F_emp).reshape(-1,1)\n",
    "    l = LinearRegression(fit_intercept=False, n_jobs=1).fit(x,y)\n",
    "    return l.coef_[0,0]\n",
    "\n",
    "def plot_components(data, model, images=None, ax=None,\n",
    "                    thumb_frac=0.05, cmap='gray'):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    proj = model.fit_transform(data)\n",
    "    ax.plot(proj[:, 0], proj[:, 1], '.k')\n",
    "    \n",
    "    if images is not None:\n",
    "        min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2\n",
    "        shown_images = np.array([2 * proj.max(0)])\n",
    "        for i in range(data.shape[0]):\n",
    "            dist = np.sum((proj[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < min_dist_2:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.vstack([shown_images, proj[i]])\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(images[i], cmap=cmap),\n",
    "                                      proj[i])\n",
    "            ax.add_artist(imagebox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "mod = Isomap(n_components=2)\n",
    "xx = torch.load('S_features_resnet50_4096')\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_components(xx, model=mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "X = xx\n",
    "distorsions = []\n",
    "for k in range(2, 20):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    distorsions.append(kmeans.inertia_)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.plot(range(2, 20), distorsions)\n",
    "plt.grid(True)\n",
    "plt.title('Elbow curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy2=np.diff(distorsions,n=2)\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.plot(range(2, 18), dy2)\n",
    "plt.grid(True)\n",
    "plt.title('Elbow curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy2=np.diff(np.log(distorsions),n=2)\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.plot(range(2, 18), dy2)\n",
    "plt.grid(True)\n",
    "plt.title('Elbow curve')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stm",
   "language": "python",
   "name": "stm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
